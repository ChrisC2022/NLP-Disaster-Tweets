{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":49330,"databundleVersionId":5211014,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**1. Brief Description of the Problem and Data:**\n\nThis Kaggle challenge (\"Natural Language Processing with Disaster Tweets\") requires natural language processing (NLP) for the purpose of analyzing tweets. These tweets may or may not be describing or alerting about a natural disaster. The challenge provides a training set and testing set; the training set includes binary target labels (1=\"disaster\", 0=\"not disaster\").\nThe training set contains $7,613$ entries. The balance of responses is asymmetric, with more tweets labeled as \"not disaster\" (57%). The following code blocks explore the training set and its characteristics. \n","metadata":{}},{"cell_type":"code","source":"#Importing the necessary packages\nimport os\nimport nltk\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:44:17.530644Z","iopub.execute_input":"2025-04-29T04:44:17.530964Z","iopub.status.idle":"2025-04-29T04:44:35.622002Z","shell.execute_reply.started":"2025-04-29T04:44:17.530928Z","shell.execute_reply":"2025-04-29T04:44:35.620625Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#Loading the train and test sets.\ntrain_data = pd.read_csv('/kaggle/input/natural-language-processing-with-disaster-tweets/train.csv')\ntest_data = pd.read_csv('/kaggle/input/natural-language-processing-with-disaster-tweets/test.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:44:38.686770Z","iopub.execute_input":"2025-04-29T04:44:38.687159Z","iopub.status.idle":"2025-04-29T04:44:38.769384Z","shell.execute_reply.started":"2025-04-29T04:44:38.687127Z","shell.execute_reply":"2025-04-29T04:44:38.768327Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"#Exploratory data analysis\ntrain_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:44:48.584905Z","iopub.execute_input":"2025-04-29T04:44:48.585318Z","iopub.status.idle":"2025-04-29T04:44:48.596381Z","shell.execute_reply.started":"2025-04-29T04:44:48.585289Z","shell.execute_reply":"2025-04-29T04:44:48.595047Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   id keyword location                                               text  \\\n0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n\n   target  \n0       1  \n1       1  \n2       1  \n3       1  \n4       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"#Taking a quick look at some of the key characteristics of the data; only the target variable here reveals anything.\ntrain_data.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:44:52.805999Z","iopub.execute_input":"2025-04-29T04:44:52.806383Z","iopub.status.idle":"2025-04-29T04:44:52.828681Z","shell.execute_reply.started":"2025-04-29T04:44:52.806356Z","shell.execute_reply":"2025-04-29T04:44:52.827725Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                 id      target\ncount   7613.000000  7613.00000\nmean    5441.934848     0.42966\nstd     3137.116090     0.49506\nmin        1.000000     0.00000\n25%     2734.000000     0.00000\n50%     5408.000000     0.00000\n75%     8146.000000     1.00000\nmax    10873.000000     1.00000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7613.000000</td>\n      <td>7613.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5441.934848</td>\n      <td>0.42966</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3137.116090</td>\n      <td>0.49506</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2734.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5408.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>8146.000000</td>\n      <td>1.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>10873.000000</td>\n      <td>1.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"**2. Exploratory Data Analysis:**\n\nThe following code blocks explore the data more thoroughly, examining the type of text present, the characteristics of relevant variables, and the distribution of labels (via histogram).","metadata":{}},{"cell_type":"code","source":"#Which types of words are used? What kinds of characters/misspellings/conjunctions/abbreviations should we expect?\ntrain_data.keyword.unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:44:56.811540Z","iopub.execute_input":"2025-04-29T04:44:56.811908Z","iopub.status.idle":"2025-04-29T04:44:56.820582Z","shell.execute_reply.started":"2025-04-29T04:44:56.811877Z","shell.execute_reply":"2025-04-29T04:44:56.819224Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n       'fire', 'fire%20truck', 'first%20responders', 'flames',\n       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"#When I printed the data sets above I noticed a lot of NAs. Is this going to be a problem for the analysis, limiting the usefulness of some variables?\nprint('Out of',len(train_data.keyword), 'values in the keyword column,', len(train_data.keyword[~pd.isna(train_data.keyword)]), 'are NA')\nprint('Out of',len(train_data.location), 'values in the keyword column,', len(train_data.location[~pd.isna(train_data.location)]), 'are NA')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:01.242183Z","iopub.execute_input":"2025-04-29T04:45:01.242558Z","iopub.status.idle":"2025-04-29T04:45:01.252582Z","shell.execute_reply.started":"2025-04-29T04:45:01.242529Z","shell.execute_reply":"2025-04-29T04:45:01.251216Z"}},"outputs":[{"name":"stdout","text":"Out of 7613 values in the keyword column, 7552 are NA\nOut of 7613 values in the keyword column, 5080 are NA\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#Thus the 'location' and 'keyword' columns probably won't be too helpful, so we'll need to focus on the actual text for our model. \n#Removing 'location' and 'keyword' columns.\ntrain_red = train_data.drop(['keyword', 'location'], axis=1)\ntrain_red.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:05.102146Z","iopub.execute_input":"2025-04-29T04:45:05.102490Z","iopub.status.idle":"2025-04-29T04:45:05.116575Z","shell.execute_reply.started":"2025-04-29T04:45:05.102466Z","shell.execute_reply":"2025-04-29T04:45:05.115525Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   id                                               text  target\n0   1  Our Deeds are the Reason of this #earthquake M...       1\n1   4             Forest fire near La Ronge Sask. Canada       1\n2   5  All residents asked to 'shelter in place' are ...       1\n3   6  13,000 people receive #wildfires evacuation or...       1\n4   7  Just got sent this photo from Ruby #Alaska as ...       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Our Deeds are the Reason of this #earthquake M...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>Forest fire near La Ronge Sask. Canada</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>All residents asked to 'shelter in place' are ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>13,000 people receive #wildfires evacuation or...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7</td>\n      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"#Dropping these columns from the test data as well.\ntest_red = test_data.drop(['keyword', 'location'], axis=1)\ntest_red.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:07.924166Z","iopub.execute_input":"2025-04-29T04:45:07.924632Z","iopub.status.idle":"2025-04-29T04:45:07.938329Z","shell.execute_reply.started":"2025-04-29T04:45:07.924594Z","shell.execute_reply":"2025-04-29T04:45:07.937185Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   id                                               text\n0   0                 Just happened a terrible car crash\n1   2  Heard about #earthquake is different cities, s...\n2   3  there is a forest fire at spot pond, geese are...\n3   9           Apocalypse lighting. #Spokane #wildfires\n4  11      Typhoon Soudelor kills 28 in China and Taiwan","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Just happened a terrible car crash</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Heard about #earthquake is different cities, s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>there is a forest fire at spot pond, geese are...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>Apocalypse lighting. #Spokane #wildfires</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"#Checking the distribution of labels in the training data.\nfig, ax = plt.subplots()\n#train_data_targets = np.sum(train_data.target==1)/len(train_data)\nax.hist(train_red.target, bins=2, density=False, rwidth=0.8)\nax.set_xticks([0.25, 0.75], ['0','1'])\nax.set_xlabel('Target (Not Disaster=0, Disaster=1)')\nax.set_ylabel('Frequency')\nax.set_title('Frequency of Natural Disasters')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:10.574018Z","iopub.execute_input":"2025-04-29T04:45:10.574426Z","iopub.status.idle":"2025-04-29T04:45:10.842609Z","shell.execute_reply.started":"2025-04-29T04:45:10.574398Z","shell.execute_reply":"2025-04-29T04:45:10.841346Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Text(0.5, 1.0, 'Frequency of Natural Disasters')"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"print('Percentage of disasters in the training data:', \n      np.round(np.sum(train_red.target[train_red.target==1])/len(train_red),2))\nprint('Percentage that were not disasters in the training data', \n      np.round((len(train_red) - np.sum(train_red.target[train_red.target==1]))/len(train_red),2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:14.074135Z","iopub.execute_input":"2025-04-29T04:45:14.074474Z","iopub.status.idle":"2025-04-29T04:45:14.083690Z","shell.execute_reply.started":"2025-04-29T04:45:14.074448Z","shell.execute_reply":"2025-04-29T04:45:14.082575Z"}},"outputs":[{"name":"stdout","text":"Percentage of disasters in the training data: 0.43\nPercentage that were not disasters in the training data 0.57\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"**3. Model Architecture:**\n\nThe model will need to be able to interpret text data to understand, learn, and predict which are indicative of actual disasters. Text strings can continue a lot of meaningless, filler, or connecting values; thus the first step will be to identify 'important' or meaningful words in the text entries and strip out the rest.\n\nThe architecture used to build the model will therefore include the following processes and steps:\n1. Tokenization of the text to enable its interpretation in a neural network;\n2. Creating a full corpus from which to work (by combining all text messages, and then seeing which texts have which specific text elements);\n3. Removal of stop words, as a basic process for improving the semantic template;\n4. Transformation of text into numeric sequences for the purpose of model heuristics;\n5. Construction of a sequential model. An embedding layer that accounted for the dimensions of the word index was added, an LSTM layer, a dense layer after the LSTM layer, and finally an output layer that used the sigmoid activation function, which is common for binary outputs (in this case, \"disaster\" vs. \"not disaster\").\n6. Training the model on the training set over $10$ epochs, with batch size $32$.","metadata":{}},{"cell_type":"code","source":"#Defining the stop words that will be filtered out.\n\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:17.923599Z","iopub.execute_input":"2025-04-29T04:45:17.924061Z","iopub.status.idle":"2025-04-29T04:45:17.934655Z","shell.execute_reply.started":"2025-04-29T04:45:17.924020Z","shell.execute_reply":"2025-04-29T04:45:17.933599Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#Creating a function to filter the stop words for each entry.\nfrom nltk.tokenize import word_tokenize\n\ndef rem_stop_words(data, stop_words):\n    new_text_body = []\n    for i in range(len(data)):\n        tokens = word_tokenize(data[i])\n        imp_words = [word for word in tokens if word.lower() not in stop_words]\n        new_text_body.append(imp_words)\n    return new_text_body","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:21.740220Z","iopub.execute_input":"2025-04-29T04:45:21.740567Z","iopub.status.idle":"2025-04-29T04:45:21.746381Z","shell.execute_reply.started":"2025-04-29T04:45:21.740540Z","shell.execute_reply":"2025-04-29T04:45:21.745076Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#Now applying the function to the training data.\nnew_text_body = rem_stop_words(data=train_red.text, stop_words=stop_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:23.816579Z","iopub.execute_input":"2025-04-29T04:45:23.817014Z","iopub.status.idle":"2025-04-29T04:45:25.581642Z","shell.execute_reply.started":"2025-04-29T04:45:23.816975Z","shell.execute_reply":"2025-04-29T04:45:25.580227Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#Creating a function that will generate a full text corpus from which the important values will be identified.\ndef create_text_body(data):\n    text_body = []\n    for i in range(len(data)):\n        comment = data[i]\n        text_body.append(comment)\n    return text_body","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:27.452560Z","iopub.execute_input":"2025-04-29T04:45:27.452970Z","iopub.status.idle":"2025-04-29T04:45:27.457940Z","shell.execute_reply.started":"2025-04-29T04:45:27.452939Z","shell.execute_reply":"2025-04-29T04:45:27.456700Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"#Using the above function to create the corpus of text for the problem.\ntext_body = create_text_body(new_text_body)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:30.007587Z","iopub.execute_input":"2025-04-29T04:45:30.007971Z","iopub.status.idle":"2025-04-29T04:45:30.013686Z","shell.execute_reply.started":"2025-04-29T04:45:30.007942Z","shell.execute_reply":"2025-04-29T04:45:30.012568Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#Need to tokenize the text for analysis, and then convert it into sequences for the model to analyze.\ntokenizer = Tokenizer()\n\n#Fitting the tokenizer to the training corpus.\ntokenizer.fit_on_texts(text_body)\n\n#Now transforming the text to integer sequences with which the neural network can work.\nsequences = tokenizer.texts_to_sequences(text_body)\n#print(sequences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:32.553939Z","iopub.execute_input":"2025-04-29T04:45:32.554377Z","iopub.status.idle":"2025-04-29T04:45:32.734580Z","shell.execute_reply.started":"2025-04-29T04:45:32.554346Z","shell.execute_reply":"2025-04-29T04:45:32.733453Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#Taking a look at the words as a quick check.\nword_index = tokenizer.word_index\n#print(word_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:35.037289Z","iopub.execute_input":"2025-04-29T04:45:35.037622Z","iopub.status.idle":"2025-04-29T04:45:35.042110Z","shell.execute_reply.started":"2025-04-29T04:45:35.037596Z","shell.execute_reply":"2025-04-29T04:45:35.041002Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"#Padding the sequences to make them the same length for analysis.\nmax_len = 10  #Arbitrary\npadded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')\nprint(padded_sequences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:45:37.060020Z","iopub.execute_input":"2025-04-29T04:45:37.060559Z","iopub.status.idle":"2025-04-29T04:45:37.094015Z","shell.execute_reply.started":"2025-04-29T04:45:37.060523Z","shell.execute_reply":"2025-04-29T04:45:37.092658Z"}},"outputs":[{"name":"stdout","text":"[[ 4406   738     3 ...    41     0     0]\n [  120    21   160 ...  1085     0     0]\n [  567    11  6749 ...   567  1261  1029]\n ...\n [ 1459    36     4 ...     2     1  6708]\n [ 5228     5  3032 ...  2452   224     5]\n [  447   124    44 ...     2     1 23078]]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import tensorflow as tf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:46:00.838795Z","iopub.execute_input":"2025-04-29T04:46:00.839204Z","iopub.status.idle":"2025-04-29T04:46:00.843373Z","shell.execute_reply.started":"2025-04-29T04:46:00.839174Z","shell.execute_reply":"2025-04-29T04:46:00.842327Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"#Leaving here for iteration and tweaking of the model's hyperparameters.\n#tf.keras.backend.clear_session()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:53:20.856987Z","iopub.execute_input":"2025-04-14T10:53:20.857231Z","iopub.status.idle":"2025-04-14T10:53:20.871600Z","shell.execute_reply.started":"2025-04-14T10:53:20.857210Z","shell.execute_reply":"2025-04-14T10:53:20.870529Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"#Building the model using the architecture described above.\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\n\n#Setting the architecture\nmodel1 = Sequential()\nmodel1.add(Embedding(len(word_index) + 1, 100, input_length=max_len))  \nmodel1.add(LSTM(128)) #was 128\n#model1.add(Dense(1024, activation='sigmoid')) #New layer. Didn't do much.\nmodel1.add(Dense(1, activation='sigmoid')) \n\n#Compiling\nmodel1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'f1_score'])\n\n#Training\nmodel1.fit(padded_sequences, train_data.target, epochs=10, batch_size=32) #Tried a variety, sticking with this as nothing improved.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:46:03.411667Z","iopub.execute_input":"2025-04-29T04:46:03.412073Z","iopub.status.idle":"2025-04-29T04:46:57.432938Z","shell.execute_reply.started":"2025-04-29T04:46:03.412042Z","shell.execute_reply":"2025-04-29T04:46:57.432035Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - accuracy: 0.6699 - f1_score: 0.5984 - loss: 0.5978\nEpoch 2/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.8927 - f1_score: 0.6060 - loss: 0.2835\nEpoch 3/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9564 - f1_score: 0.6037 - loss: 0.1253\nEpoch 4/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9798 - f1_score: 0.5950 - loss: 0.0574\nEpoch 5/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9863 - f1_score: 0.6019 - loss: 0.0423\nEpoch 6/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9886 - f1_score: 0.5972 - loss: 0.0279\nEpoch 7/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9895 - f1_score: 0.6092 - loss: 0.0219\nEpoch 8/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9924 - f1_score: 0.6010 - loss: 0.0174\nEpoch 9/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9924 - f1_score: 0.6051 - loss: 0.0199\nEpoch 10/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9933 - f1_score: 0.5995 - loss: 0.0168\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7bf22d981e70>"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"**4. Results and Analysis:**\n\n**a) Discussion of Results from the First Model:**\n\nRunning the model before and after removing stop words, and before and after adding an intermittent layer, resulted in high accuracy (0.99) but an f1-score hovering around 0.6. One possible option would be to go back to the beginning and examine whether the words of any text are mentioned in that highly suggestive 'keyword' column which was removed because there were so few entries. In these next code blocks that's what I'll do, and we'll see whether focusing on the frequency or appearance of keywords improves the model's performance.\n","metadata":{}},{"cell_type":"code","source":"#Nan is the first value in the unique keyword array; eliminating it to create a list of useful words.\nuseful_keywords = train_data.keyword.unique()[1:]\nprint(type(useful_keywords))\nuseful_keywords = set(useful_keywords.astype(str))\n\n#Function to replace the '%20' (or anything else that pops up) from the strings, to allow comparison and remove meaningless characters.\ndef repl_str(prev, repl):\n    new_keywords = set()\n    for word in prev:\n        for old, new in repl.items():\n            word = word.replace(old, new)\n        new_keywords.add(word)\n    return new_keywords\n\nrepl_dct = {'%20': ' '}\nnew_keywords = repl_str(useful_keywords, repl_dct)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:47:01.743778Z","iopub.execute_input":"2025-04-29T04:47:01.744176Z","iopub.status.idle":"2025-04-29T04:47:01.752429Z","shell.execute_reply.started":"2025-04-29T04:47:01.744142Z","shell.execute_reply":"2025-04-29T04:47:01.751391Z"}},"outputs":[{"name":"stdout","text":"<class 'numpy.ndarray'>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"#Here are our new keywords:\nprint(new_keywords)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:47:04.455684Z","iopub.execute_input":"2025-04-29T04:47:04.456135Z","iopub.status.idle":"2025-04-29T04:47:04.461227Z","shell.execute_reply.started":"2025-04-29T04:47:04.456072Z","shell.execute_reply":"2025-04-29T04:47:04.460019Z"}},"outputs":[{"name":"stdout","text":"{'smoke', 'fire truck', 'cyclone', 'derailment', 'deaths', 'deluged', 'outbreak', 'natural disaster', 'nuclear reactor', 'panic', 'oil spill', 'bomb', 'radiation emergency', 'bioterrorism', 'drought', 'buildings on fire', 'tragedy', 'rescued', 'disaster', 'eyewitness', 'stretcher', 'explode', 'forest fire', 'blood', 'wildfire', 'wounded', 'violent storm', 'screamed', 'burning', 'crush', 'chemical emergency', 'obliteration', 'desolate', 'thunder', 'mass murderer', 'displaced', 'demolished', 'engulfed', 'ruin', 'hijack', 'trapped', 'wreckage', 'blew up', 'bombing', 'collide', 'danger', 'screams', 'catastrophe', 'exploded', 'ambulance', 'deluge', 'traumatised', 'quarantine', 'obliterated', 'burned', 'typhoon', 'crushed', 'hellfire', 'weapons', 'attack', 'flooding', 'drowned', 'evacuate', 'damage', 'destruction', 'emergency services', 'harm', 'riot', 'forest fires', 'twister', 'derailed', 'terrorism', 'evacuation', 'pandemonium', 'arsonist', 'suicide bomb', 'hostages', 'inundated', 'quarantined', 'armageddon', 'bombed', 'detonation', 'first responders', 'emergency', 'mass murder', 'thunderstorm', 'hazard', 'snowstorm', 'survivors', 'military', 'emergency plan', 'cliff fall', 'fear', 'hurricane', 'tsunami', 'sinkhole', 'derail', 'collapse', 'nuclear disaster', 'rainstorm', 'wreck', 'body bag', 'explosion', 'electrocute', 'death', 'lightning', 'mudslide', 'rescuers', 'crash', 'electrocuted', 'hail', 'blizzard', 'obliterate', 'flames', 'sunk', 'meltdown', 'destroy', 'terrorist', 'attacked', 'injury', 'police', 'collision', 'rescue', 'floods', 'fire', 'bioterror', 'upheaval', 'ablaze', 'storm', 'casualty', 'fatalities', 'collided', 'battle', 'casualties', 'dust storm', 'annihilated', 'detonate', 'accident', 'siren', 'tornado', 'demolish', 'rubble', 'mayhem', 'debris', 'hazardous', 'bloody', 'inundation', 'hailstorm', 'burning buildings', 'crashed', 'arson', 'body bagging', 'drowning', 'epicentre', 'body bags', 'army', 'hijacking', 'sirens', 'wrecked', 'flattened', 'bleeding', 'buildings burning', 'devastation', 'bridge collapse', 'suicide bomber', 'blight', 'sinking', 'screaming', 'suicide bombing', 'massacre', 'dead', 'survive', 'flood', 'heat wave', 'apocalypse', 'desolation', 'windstorm', 'avalanche', 'annihilation', 'blaze', 'rioting', 'survived', 'collapsed', 'wild fires', 'bush fires', 'hijacker', 'blown up', 'demolition', 'famine', 'evacuated', 'earthquake', 'hostage', 'injuries', 'refugees', 'landslide', 'war zone', 'fatality', 'lava', 'razed', 'loud bang', 'drown', 'whirlwind', 'aftershock', 'airplane accident', 'curfew', 'destroyed', 'volcano', 'threat', 'fatal', 'trauma', 'panicking', 'weapon', 'trouble', 'structural failure', 'seismic', 'catastrophic', 'blazing', 'injured', 'devastated', 'sandstorm', 'wounds'}\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"#Modifying earlier function to focus on keywords:\ndef keep_keywords(data, keep_words):\n    new_text_body = []\n    for i in range(len(data)):\n        tokens = word_tokenize(data[i])\n        imp_words = [word for word in tokens if word.lower() in keep_words]\n        new_text_body.append(imp_words)\n    return new_text_body","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:47:07.116662Z","iopub.execute_input":"2025-04-29T04:47:07.117183Z","iopub.status.idle":"2025-04-29T04:47:07.124154Z","shell.execute_reply.started":"2025-04-29T04:47:07.117141Z","shell.execute_reply":"2025-04-29T04:47:07.122655Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"#Now calling the function to focus on those words:\nkeyword_textbody = keep_keywords(data=train_red.text, keep_words=new_keywords)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:47:09.475856Z","iopub.execute_input":"2025-04-29T04:47:09.476266Z","iopub.status.idle":"2025-04-29T04:47:11.267605Z","shell.execute_reply.started":"2025-04-29T04:47:09.476233Z","shell.execute_reply":"2025-04-29T04:47:11.266524Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"#Tokenizing, fitting to texts, and generating sequences\nkwrd_text_body = create_text_body(keyword_textbody)\n\ntokenizer2 = Tokenizer()\n\ntokenizer2.fit_on_texts(kwrd_text_body)\n\nsequences2 = tokenizer2.texts_to_sequences(kwrd_text_body)\n#print(sequences2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:47:13.990039Z","iopub.execute_input":"2025-04-29T04:47:13.990465Z","iopub.status.idle":"2025-04-29T04:47:14.018370Z","shell.execute_reply.started":"2025-04-29T04:47:13.990437Z","shell.execute_reply":"2025-04-29T04:47:14.017108Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"#Padding the sequences.\npadded_sequences2 = pad_sequences(sequences2, maxlen=max_len, padding='post')\nprint(padded_sequences2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:47:17.061806Z","iopub.execute_input":"2025-04-29T04:47:17.062315Z","iopub.status.idle":"2025-04-29T04:47:17.096715Z","shell.execute_reply.started":"2025-04-29T04:47:17.062275Z","shell.execute_reply":"2025-04-29T04:47:17.095687Z"}},"outputs":[{"name":"stdout","text":"[[ 29   0   0 ...   0   0   0]\n [  1   0   0 ...   0   0   0]\n [ 26   0   0 ...   0   0   0]\n ...\n [148   0   0 ...   0   0   0]\n [  4  46  35 ...   0   0   0]\n [134  14   0 ...   0   0   0]]\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"word_index2 = tokenizer2.word_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:47:24.523242Z","iopub.execute_input":"2025-04-29T04:47:24.523573Z","iopub.status.idle":"2025-04-29T04:47:24.528104Z","shell.execute_reply.started":"2025-04-29T04:47:24.523547Z","shell.execute_reply":"2025-04-29T04:47:24.526932Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"#Setting the architecture\nmodel2 = Sequential()\nmodel2.add(Embedding(len(word_index2) + 1, 100, input_length=max_len))  \nmodel2.add(LSTM(128))\nmodel2.add(Dense(1, activation='sigmoid')) \n\n#Compiling\nmodel2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', 'f1_score'])\n\n#Training\nmodel2.fit(padded_sequences2, train_data.target, epochs=10, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:47:26.488814Z","iopub.execute_input":"2025-04-29T04:47:26.489215Z","iopub.status.idle":"2025-04-29T04:48:00.527021Z","shell.execute_reply.started":"2025-04-29T04:47:26.489180Z","shell.execute_reply":"2025-04-29T04:48:00.526030Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.6128 - f1_score: 0.6078 - loss: 0.6529\nEpoch 2/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7225 - f1_score: 0.6034 - loss: 0.5552\nEpoch 3/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7314 - f1_score: 0.6073 - loss: 0.5487\nEpoch 4/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7433 - f1_score: 0.6047 - loss: 0.5305\nEpoch 5/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7410 - f1_score: 0.6049 - loss: 0.5321\nEpoch 6/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7372 - f1_score: 0.5933 - loss: 0.5356\nEpoch 7/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7380 - f1_score: 0.6021 - loss: 0.5341\nEpoch 8/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7383 - f1_score: 0.6000 - loss: 0.5323\nEpoch 9/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7390 - f1_score: 0.6032 - loss: 0.5263\nEpoch 10/10\n\u001b[1m238/238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7407 - f1_score: 0.6013 - loss: 0.5248\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7bf1d81bf9d0>"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"**4. Results and Analysis (continued):**\n\n**b) Discussion of Results from the Second Model:**\n\nThere was a steep drop in accuracy without much improvement in f1-score. Keeping with the first model.","metadata":{}},{"cell_type":"markdown","source":"**c) Applying the first model to the test data and generating output:**\n\nTo apply the model, I'll first prepare the test data for analysis using the functions I implemented above: rem_stop_words (to remove stop words from the test data), create_text_body (to create a corpus for analysis), and package-provided fit_on_texts, texts_to_sequences, and pad_sequences. Then the model will generate predictions of disaster or not based on the provided text>\n\nFrom there, I'll output the predictions into a .csv file and submit it to the competition. ","metadata":{}},{"cell_type":"code","source":"#Predicting with test data set. Following the above steps to prepare the test data, and then applying the model:\ntest_text_body = rem_stop_words(data=test_red.text, stop_words=stop_words)\n \nnew_test_text_body = create_text_body(test_text_body)\n\ntokenizer.fit_on_texts(new_test_text_body)\n\ntest_sequences = tokenizer.texts_to_sequences(new_test_text_body)\n\npadded_test_seqs = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n\ny_preds = model1.predict(padded_test_seqs)\noutput = (y_preds<0.5).astype(int)\n#print(output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:52:03.707417Z","iopub.execute_input":"2025-04-29T04:52:03.707779Z","iopub.status.idle":"2025-04-29T04:52:05.353179Z","shell.execute_reply.started":"2025-04-29T04:52:03.707751Z","shell.execute_reply":"2025-04-29T04:52:05.352027Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"#Preparing the predictions for the output file.\noutput_vals = []\nfor i in range(len(output)):\n    val = output[i][0]\n    output_vals.append(val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:52:29.013763Z","iopub.execute_input":"2025-04-29T04:52:29.014168Z","iopub.status.idle":"2025-04-29T04:52:29.020535Z","shell.execute_reply.started":"2025-04-29T04:52:29.014129Z","shell.execute_reply":"2025-04-29T04:52:29.019228Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"#Creating the submission file.\nsubmission = pd.DataFrame({'id': test_data.id, 'target':output_vals})\nprint(submission.head())\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-29T04:52:37.539873Z","iopub.execute_input":"2025-04-29T04:52:37.540314Z","iopub.status.idle":"2025-04-29T04:52:37.564070Z","shell.execute_reply.started":"2025-04-29T04:52:37.540273Z","shell.execute_reply":"2025-04-29T04:52:37.562885Z"}},"outputs":[{"name":"stdout","text":"   id  target\n0   0       1\n1   2       0\n2   3       1\n3   9       0\n4  11       1\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"**5. Conclusion**\n\nThe model used sequential layers with embeddings, LSTM, and an output layer that featured the sigmoid activiation function. While the model was able to achieve excellent accuracy on the training data, the f1-score continued to hover around $0.6$, even after numerous adjustments to the hyperparameters. One final adjustment was made in the processing of data, i.e., leveraging disaster-related keywords to help the model learn which words would be more likely to be associated with disasters; contrary to expectations, this approach actually decreased the accuracy while maintaining similar f1-scores, and was not used in the final model.\n\nAlternative approaches and methods for interpreting text data for deep learning models exist and will likely be attempted as part of an iterative process of improving f1-scores for this challenge.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T10:53:01.600759Z","iopub.execute_input":"2025-04-14T10:53:01.601181Z","iopub.status.idle":"2025-04-14T10:53:02.014405Z","shell.execute_reply.started":"2025-04-14T10:53:01.601151Z","shell.execute_reply":"2025-04-14T10:53:02.013452Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/natural-language-processing-with-disaster-tweets/sample_submission.csv\n/kaggle/input/natural-language-processing-with-disaster-tweets/train.csv\n/kaggle/input/natural-language-processing-with-disaster-tweets/test.csv\n","output_type":"stream"}],"execution_count":1}]}